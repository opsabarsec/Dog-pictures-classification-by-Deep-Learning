{"cells":[{"metadata":{},"cell_type":"markdown","source":"# RESnet50 transfer learning"},{"metadata":{},"cell_type":"markdown","source":"## 1. Import libraries and load data"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\n#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n#os.environ[\"AUTOGRAPH_VERBOSITY\"] = \"10\"\nos.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\nfrom tqdm import tqdm \nimport time \nfrom platform import python_version\nimport warnings\nimport time\nimport datetime as dt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nimport multiprocessing as mp\nimport shutil\nimport cv2\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.resnet50 import ResNet50, decode_predictions, preprocess_input\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.utils import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.initializers import *\nfrom tensorflow_addons.layers import WeightNormalization\nfrom sklearn.metrics import classification_report\n\n\nfrom wandb.keras import WandbCallback\nimport pandas as pd\nimport numpy as np\nimport seaborn as sn\n\nfrom PIL import Image\nimport xml.etree.ElementTree as ET\nimport psutil\nimport random\n\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n\nprint(\"py\", python_version())\nprint(\"tf\", tf.__version__)\nprint(\"keras\", tf.keras.__version__)\nmem = psutil.virtual_memory()\nprint(\"mem\", mem.total/1024/1024)\ncpu = mp.cpu_count()\nprint(\"cpu\", cpu)\n\n%system nvidia-smi\n#%system rocm-smi","execution_count":1,"outputs":[{"output_type":"stream","text":"py 3.7.6\ntf 2.2.0\nkeras 2.3.0-tf\nmem 16045.11328125\ncpu 2\n","name":"stdout"},{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"['Fri Jul 24 15:16:27 2020       ',\n '+-----------------------------------------------------------------------------+',\n '| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |',\n '|-------------------------------+----------------------+----------------------+',\n '| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |',\n '| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |',\n '|===============================+======================+======================|',\n '|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |',\n '| N/A   38C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |',\n '+-------------------------------+----------------------+----------------------+',\n '                                                                               ',\n '+-----------------------------------------------------------------------------+',\n '| Processes:                                                       GPU Memory |',\n '|  GPU       PID   Type   Process name                             Usage      |',\n '|=============================================================================|',\n '|  No running processes found                                                 |',\n '+-----------------------------------------------------------------------------+']"},"metadata":{}}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data_dir = '../input/stanford-dogs-dataset/images/Images'\nannotations_dir = '../input/stanford-dogs-dataset/annotations/Annotation' ","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.1 variables"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"breed_list = os.listdir(data_dir)\nprint(\"num. breeds total:\", len(breed_list))\n\n\n# Print out the classes we need to target\nclass_names = [breed.split('-',1)[1] for breed in breed_list] #visualize breeds\nprint(class_names[:10])","execution_count":3,"outputs":[{"output_type":"stream","text":"num. breeds total: 120\n['Weimaraner', 'affenpinscher', 'Chesapeake_Bay_retriever', 'Sussex_spaniel', 'Leonberg', 'Maltese_dog', 'Saluki', 'kelpie', 'keeshond', 'American_Staffordshire_terrier']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 2. Image preprocessing"},{"metadata":{},"cell_type":"markdown","source":"### 2.1 Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_of_categories = 120\nimage_size = 192\nbatch_size = 16","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_breeds = 120 # integer between 2 and 120\nbreeds = breed_list[:num_breeds]\n\ndef load_images_and_labels(breeds):\n    img_lst=[]\n    labels=[]\n    \n    for index, breed in tqdm(enumerate(breeds)):\n        for image_name in os.listdir(data_dir+\"/\"+breed):\n            img = cv2.imread(data_dir+\"/\"+breed+\"/\"+image_name)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                       \n            img_array = Image.fromarray(img, 'RGB')\n            \n            #resize image to 224 x 224 because the input image resolution for ResNet50 is 224 x 224\n            resized_img = img_array.resize((224, 224))\n            \n            img_lst.append(np.array(resized_img)) # append image as numpy array\n            \n            labels.append(class_names[index])\n            \n    return img_lst, labels \n\nimages, labels = load_images_and_labels(breeds)\nprint(\"No. of images loaded = \",len(images),\"\\nNo. of labels loaded = \",len(labels))","execution_count":5,"outputs":[{"output_type":"stream","text":"120it [03:02,  1.52s/it]","name":"stderr"},{"output_type":"stream","text":"No. of images loaded =  20580 \nNo. of labels loaded =  20580\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"### 2.2 label encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace numbers with names\nle = LabelEncoder()\nnlabels = le.fit_transform(labels) # encode labels as number values. This prepares for categorical encoding\nY=to_categorical(nlabels,num_classes = num_breeds) # category encoding","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(images)","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3 test and train sets "},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\n\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=1)\n\nprint(\"x_train shape = \",x_train.shape)\nprint(\"y_train shape = \",y_train.shape)\n\nprint(\"\\nx_val shape = \",x_val.shape)\nprint(\"y_val shape = \",y_val.shape)\n\nprint(\"\\nx_test shape = \",x_test.shape)\nprint(\"y_test shape = \",y_test.shape)","execution_count":8,"outputs":[{"output_type":"stream","text":"x_train shape =  (14817, 224, 224, 3)\ny_train shape =  (14817, 120)\n\nx_val shape =  (1647, 224, 224, 3)\ny_val shape =  (1647, 120)\n\nx_test shape =  (4116, 224, 224, 3)\ny_test shape =  (4116, 120)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### 2.4 features preprocess"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We should preprocess the images the same way resnet images were preprocessed\naug = ImageDataGenerator(rotation_range=30, #rotations (as seen above)\n                        width_shift_range=0.2,  # randomly shift images horizontally \n                        height_shift_range=0.2,# randomly shift images vertically \n                        shear_range=0.2, # shear image\n                        zoom_range=0.2, # zoom into image \n                        horizontal_flip=True, # randomly flip images\n                        rescale=1/255., #rescale array values\n                        preprocessing_function=preprocess_input) #  creates a ‘reflection’ and fills the empty values in reverse order of the known values\n\n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load ResNet50 Trained on imagenet\nresnet_model = ResNet50(weights=\"imagenet\")\n","execution_count":11,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n102973440/102967424 [==============================] - 1s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build a new model that is ResNet50 minus the very last layer\nlast_layer = resnet_model.get_layer(\"avg_pool\")\n\nresnet_layers = keras.Model(inputs=resnet_model.inputs, outputs=last_layer.output)\n","execution_count":10,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'resnet_model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-24cf66a4e1e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build a new model that is ResNet50 minus the very last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlast_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"avg_pool\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresnet_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'resnet_model' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We use our resnet to \"predict\" but because we have removed the top layer, \n# this outputs the activations of the second to last layer on our dataset\n\nx_train_features = resnet_layers.predict(x_train_preprocessed)\n\n\nx_test_features = resnet_layers.predict(x_test_preprocessed)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define new top layers and compile model"},{"metadata":{"trusted":false},"cell_type":"code","source":"feature_model=Sequential()\nfeature_model.add(Dense(120, activation=\"sigmoid\"))\nfeature_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wandb.init(project=\"transfer learn\")\nfeature_model.fit(x_train_features, y_train, epochs=50, validation_data=(x_test_features, y_test), callbacks=[WandbCallback()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"optimizer = Adam(lr=learning_rate)\n# optimizer = RMSprop(lr=learning_rate)\n\nloss = \"categorical_crossentropy\"\n# loss = \"kullback_leibler_divergence\"\n\nfor layer in model.layers:\n    layer.trainable = True\n\nmodel.compile(optimizer=optimizer,\n              loss=loss,\n              metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(x_test, y_test)\n\nprint(test_loss,test_accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fit model"},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\n\nhistory_1 = model.fit_generator(generator=train_generator, \n                                steps_per_epoch=len(train_generator), \n                                validation_data=test_generator, \n                                validation_steps=len(test_generator),\n                                epochs=epochs,\n                                callbacks=[reducelr, earlystop, lambdacb, tensorboard, checkpoint])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training and test loss/accuracy graphs"},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(18, 6))\n\nplt.subplot(121)\nloss = history_1.history['loss']\nval_loss = history_1.history['val_loss']\nplt.plot(loss,\"--\", linewidth=3 , label=\"train\")\nplt.plot(val_loss, linewidth=3 , label=\"valid\")\n\nplt.legend(['train','validation'], loc='upper left')\nplt.grid()\nplt.ylabel('loss')\nplt.ylim((1.5, 3))\nplt.xlabel('Epoch')\nplt.title('4 layers CNN Model Loss')\nplt.legend(['train','validation'], loc='upper left')\n\nplt.subplot(122)\nacc = history_1.history['accuracy']\nval_acc = history_1.history['val_accuracy']\n\nplt.plot(acc,\"--\", linewidth=3 , label=\"train\")\nplt.plot(val_acc, linewidth=3 , label=\"valid\")\n\nplt.legend(['train','validation'], loc='upper left')\nplt.grid()\n\nplt.ylabel('accuracy')\nplt.xlabel('Epoch')\nplt.title('4 layers CNN Model accuracy')\nplt.legend(['train','validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sample prediction"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Randomly test an image from the test set\n\n# model.load_weights('dog_breed_classifier.h5')\n\nimageno=np.random.random_integers(low=0, high=test_generator.samples)\n\nname = test_generator.filepaths[imageno]\nprint(name)\nplt.imshow(mpimg.imread(name))\n\nimg = Image.open(test_generator.filepaths[imageno]).resize((targetx, targety))\nprobabilities = model.predict(preprocess_input(np.expand_dims(img, axis=0)))\nbreed_list = tuple(zip(test_generator.class_indices.values(), test_generator.class_indices.keys()))\n\nfor i in probabilities[0].argsort()[-5:][::-1]: \n    print(probabilities[0][i], \"  :  \" , breed_list[i])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}